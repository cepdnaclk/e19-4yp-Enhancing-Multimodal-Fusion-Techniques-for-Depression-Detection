{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab449a7-8087-40de-8b71-caf5a1614f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "# ----------- STEP 1: LOAD AND INSPECT THE DATA -----------\n",
    "df = pd.read_parquet(\"../data/processed/all_user_combined_data_processed.parquet\")\n",
    "\n",
    "print(\"=== Dataset Overview ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\n--- Data Types ---\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n--- First 5 rows ---\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n--- Statistical Summary ---\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "\n",
    "target_col = 'Depression_label'  \n",
    "if target_col in df.columns:\n",
    "    print(f\"\\n--- Target Variable ('{target_col}') Distribution ---\")\n",
    "    print(df[target_col].value_counts(normalize=True))\n",
    "else:\n",
    "    print(f\"Target column '{target_col}' not found!\")\n",
    "\n",
    "# ----------- STEP 2: CHECK FOR MISSING DATA -----------\n",
    "print(\"\\n=== Missing Data ===\")\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(missing)\n",
    "\n",
    "# Visualize missing data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# ----------- STEP 3: STATISTICAL SUMMARY & TARGET BALANCE -----------\n",
    "# Numeric columns summary\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "print(\"\\n=== Numeric Features Summary ===\")\n",
    "print(df[numeric_cols].describe())\n",
    "\n",
    "# Categorical columns summary\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "print(\"\\n=== Categorical Features Summary ===\")\n",
    "for col in cat_cols:\n",
    "    print(f\"\\nValue counts for {col}:\")\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "# Plot target variable balance\n",
    "if target_col in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.countplot(data=df, x=target_col)\n",
    "    plt.title('Target Variable Distribution')\n",
    "    plt.show()\n",
    "\n",
    "# ----------- STEP 4: FEATURE RELATIONSHIPS -----------\n",
    "\n",
    "# Correlation matrix for numeric features\n",
    "plt.figure(figsize=(12,10))\n",
    "corr = df[numeric_cols].corr()\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix for Numeric Features')\n",
    "plt.show()\n",
    "\n",
    "# Point-biserial correlations of numeric features with binary target\n",
    "def compute_pointbiserial_correlations(df, feature_cols, label_col):\n",
    "    correlations = {}\n",
    "    for col in feature_cols:\n",
    "        if col == label_col:\n",
    "            continue\n",
    "        try:\n",
    "            if df[col].nunique() > 1:\n",
    "                corr, pval = pointbiserialr(df[label_col], df[col])\n",
    "                correlations[col] = (corr, pval)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {col} due to error: {e}\")\n",
    "    return pd.DataFrame.from_dict(correlations, orient='index', columns=['Correlation', 'p-value']).sort_values('Correlation', ascending=False)\n",
    "\n",
    "if target_col in df.columns:\n",
    "    pb_corr_df = compute_pointbiserial_correlations(df, numeric_cols, target_col)\n",
    "    print(\"\\n=== Point-Biserial Correlations with Target ===\")\n",
    "    print(pb_corr_df.head(10))\n",
    "\n",
    "# ----------- STEP 5: VISUALIZATIONS -----------\n",
    "\n",
    "# Histograms / distributions of features grouped by target\n",
    "for col in numeric_cols:\n",
    "    if col == target_col:\n",
    "        continue\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(data=df, x=col, hue=target_col, kde=True, element='step', stat='density')\n",
    "    plt.title(f'Distribution of {col} by {target_col}')\n",
    "    plt.show()\n",
    "\n",
    "# Boxplots of numeric features by target\n",
    "for col in numeric_cols:\n",
    "    if col == target_col:\n",
    "        continue\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.boxplot(data=df, x=target_col, y=col)\n",
    "    plt.title(f'{col} by {target_col}')\n",
    "    plt.show()\n",
    "\n",
    "# Pairplot (limited to few features to avoid overload)\n",
    "subset_features = numeric_cols[:5] + [target_col] if target_col in df.columns else numeric_cols[:5]\n",
    "sns.pairplot(df[subset_features], hue=target_col, diag_kind='kde')\n",
    "plt.show()\n",
    "\n",
    "# ----------- STEP 6: DETECT OUTLIERS AND ANOMALIES -----------\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate Z-scores and flag outliers for numeric features\n",
    "outliers = {}\n",
    "for col in numeric_cols:\n",
    "    if col == target_col:\n",
    "        continue\n",
    "    z_scores = np.abs(zscore(df[col].dropna()))\n",
    "    outlier_indices = df[col].dropna().index[z_scores > 3].tolist()\n",
    "    outliers[col] = len(outlier_indices)\n",
    "\n",
    "print(\"\\n=== Number of Outliers per Numeric Feature (Z-score > 3) ===\")\n",
    "for col, count in outliers.items():\n",
    "    print(f\"{col}: {count}\")\n",
    "\n",
    "# Visualize outliers using boxplots already above, or:\n",
    "\n",
    "# ----------- STEP 7: FEATURE ENGINEERING INSIGHTS -----------\n",
    "\n",
    "print(\"\\n--- Feature Engineering Insights ---\")\n",
    "\n",
    "# Check for constant features (zero variance)\n",
    "constant_features = [col for col in df.columns if df[col].nunique() == 1]\n",
    "print(f\"Constant features (zero variance): {constant_features}\")\n",
    "\n",
    "# Check for duplicated columns (optional)\n",
    "duplicated_cols = []\n",
    "for i in range(len(df.columns)):\n",
    "    for j in range(i + 1, len(df.columns)):\n",
    "        if df.iloc[:, i].equals(df.iloc[:, j]):\n",
    "            duplicated_cols.append((df.columns[i], df.columns[j]))\n",
    "print(f\"Duplicated columns: {duplicated_cols}\")\n",
    "\n",
    "# Suggest scaling for numeric features (can use StandardScaler or MinMaxScaler later)\n",
    "print(\"Consider scaling numeric features before modeling.\")\n",
    "\n",
    "# Encoding for categorical features (e.g., one-hot or label encoding)\n",
    "print(f\"Categorical features to encode: {cat_cols}\")\n",
    "\n",
    "# ----------- STEP 8: DATA QUALITY AND BIAS CHECK -----------\n",
    "\n",
    "print(\"\\n--- Data Quality & Bias Checks ---\")\n",
    "\n",
    "# Check data distribution for key demographic features like age, gender if present\n",
    "for col in ['age', 'gender']:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\nDistribution of {col}:\")\n",
    "        print(df[col].value_counts(normalize=True))\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.countplot(data=df, x=col)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.show()\n",
    "\n",
    "# Check for class imbalance in target\n",
    "if target_col in df.columns:\n",
    "    balance = df[target_col].value_counts(normalize=True)\n",
    "    print(f\"\\nClass distribution in target '{target_col}':\")\n",
    "    print(balance)\n",
    "\n",
    "# Check for duplicate rows\n",
    "dupes = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {dupes}\")\n",
    "\n",
    "# Check for impossible or suspicious values (negative ages, etc.) if domain relevant\n",
    "if 'age' in df.columns:\n",
    "    invalid_ages = df[df['age'] < 0].shape[0]\n",
    "    print(f\"Number of invalid (negative) age entries: {invalid_ages}\")\n",
    "\n",
    "print(\"\\n--- End of EDA ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90c441-ee33-47e8-89bb-cc66138ff347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
