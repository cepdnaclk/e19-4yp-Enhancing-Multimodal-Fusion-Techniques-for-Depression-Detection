{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9efd0756-463b-48af-825c-4253dea14a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Transcript for 300_P:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.3</td>\n",
       "      <td>15.1</td>\n",
       "      <td>so I'm going to</td>\n",
       "      <td>0.934210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>interview in Spanish</td>\n",
       "      <td>0.608470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.9</td>\n",
       "      <td>24.3</td>\n",
       "      <td>okay</td>\n",
       "      <td>0.690606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.1</td>\n",
       "      <td>62.7</td>\n",
       "      <td>good</td>\n",
       "      <td>0.951897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.8</td>\n",
       "      <td>69.8</td>\n",
       "      <td>Atlanta Georgia</td>\n",
       "      <td>0.987629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start_Time  End_Time                   Text  Confidence\n",
       "0        14.3      15.1        so I'm going to    0.934210\n",
       "1        20.3      21.1   interview in Spanish    0.608470\n",
       "2        23.9      24.3                   okay    0.690606\n",
       "3        62.1      62.7                   good    0.951897\n",
       "4        68.8      69.8        Atlanta Georgia    0.987629"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Transcript for 301_P:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>yeah there's also on Craigslist so that's why</td>\n",
       "      <td>0.883057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.9</td>\n",
       "      <td>42.5</td>\n",
       "      <td>okay</td>\n",
       "      <td>0.960925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.9</td>\n",
       "      <td>55.8</td>\n",
       "      <td>how are you doing today I'm doing good thank you</td>\n",
       "      <td>0.950963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.7</td>\n",
       "      <td>60.7</td>\n",
       "      <td>I'm from Los Angeles</td>\n",
       "      <td>0.970176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.4</td>\n",
       "      <td>64.2</td>\n",
       "      <td>I'm great</td>\n",
       "      <td>0.904099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start_Time  End_Time                                               Text  \\\n",
       "0         0.8       7.0      yeah there's also on Craigslist so that's why   \n",
       "1        41.9      42.5                                               okay   \n",
       "2        52.9      55.8   how are you doing today I'm doing good thank you   \n",
       "3        59.7      60.7                               I'm from Los Angeles   \n",
       "4        63.4      64.2                                          I'm great   \n",
       "\n",
       "   Confidence  \n",
       "0    0.883057  \n",
       "1    0.960925  \n",
       "2    0.950963  \n",
       "3    0.970176  \n",
       "4    0.904099  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Transcript for 302_P:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>just move around a little bit</td>\n",
       "      <td>0.906568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>when you're finished</td>\n",
       "      <td>0.793796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.2</td>\n",
       "      <td>59.1</td>\n",
       "      <td>how are you doing today</td>\n",
       "      <td>0.859790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.6</td>\n",
       "      <td>61.0</td>\n",
       "      <td>I'm fine how about yourself</td>\n",
       "      <td>0.987629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.6</td>\n",
       "      <td>67.3</td>\n",
       "      <td>where you from</td>\n",
       "      <td>0.911304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start_Time  End_Time                           Text  Confidence\n",
       "0         2.1       3.2  just move around a little bit    0.906568\n",
       "1        26.3      27.1           when you're finished    0.793796\n",
       "2        58.2      59.1        how are you doing today    0.859790\n",
       "3        59.6      61.0    I'm fine how about yourself    0.987629\n",
       "4        66.6      67.3                 where you from    0.911304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Transcript for 308_P:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>okay perfect so we just want to move around a ...</td>\n",
       "      <td>0.927091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.7</td>\n",
       "      <td>13.6</td>\n",
       "      <td>all right now you got perfect</td>\n",
       "      <td>0.758649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>okay</td>\n",
       "      <td>0.901707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>good to go now</td>\n",
       "      <td>0.755682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.9</td>\n",
       "      <td>31.1</td>\n",
       "      <td>when she's done talking to you when you go ah...</td>\n",
       "      <td>0.891598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start_Time  End_Time                                               Text  \\\n",
       "0         0.0       9.6  okay perfect so we just want to move around a ...   \n",
       "1        11.7      13.6                      all right now you got perfect   \n",
       "2        17.4      18.0                                               okay   \n",
       "3        20.0      21.0                                     good to go now   \n",
       "4        24.9      31.1   when she's done talking to you when you go ah...   \n",
       "\n",
       "   Confidence  \n",
       "0    0.927091  \n",
       "1    0.758649  \n",
       "2    0.901707  \n",
       "3    0.755682  \n",
       "4    0.891598  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Base path relative to text_preprocess.ipynb\n",
    "data_dir = os.path.join('..', 'data')\n",
    "\n",
    "# List all subject folders that end with _P\n",
    "subject_folders = [\n",
    "    folder for folder in os.listdir(data_dir)\n",
    "    if os.path.isdir(os.path.join(data_dir, folder)) and folder.endswith('_P')\n",
    "]\n",
    "\n",
    "for subject in sorted(subject_folders):\n",
    "    subject_id = subject.split('_')[0]  # e.g., '300' from '300_P'\n",
    "    transcript_path = os.path.join(data_dir, subject, 'clinical', f'{subject_id}_Transcript.csv')\n",
    "\n",
    "    if os.path.exists(transcript_path):\n",
    "        print(f\"\\n‚úÖ Transcript for {subject}:\\n\")\n",
    "        df = pd.read_csv(transcript_path)\n",
    "        display(df.head())  # or use print(df.head()) if not in Jupyter\n",
    "    else:\n",
    "        print(f\"‚ùå Transcript file not found for {subject} at path: {transcript_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39da2e2e-7676-4509-9b81-e177d4b4b29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extracting BioBERT features for 300_P - 300_Transcript.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300_P: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [00:03<00:00, 20.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved BioBERT features to: ../data/300_P/clinical/300_Transcript_biobert_features.csv\n",
      "üìä Shape: (70, 770)\n",
      "üîç Extracting BioBERT features for 302_P - 302_Transcript.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302_P: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [00:04<00:00, 19.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved BioBERT features to: ../data/302_P/clinical/302_Transcript_biobert_features.csv\n",
      "üìä Shape: (96, 770)\n",
      "üîç Extracting BioBERT features for 308_P - 308_Transcript.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "308_P: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 149/149 [00:07<00:00, 19.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved BioBERT features to: ../data/308_P/clinical/308_Transcript_biobert_features.csv\n",
      "üìä Shape: (143, 770)\n",
      "üîç Extracting BioBERT features for 301_P - 301_Transcript.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301_P: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 72/72 [00:03<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved BioBERT features to: ../data/301_P/clinical/301_Transcript_biobert_features.csv\n",
      "üìä Shape: (70, 770)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script extracts BioBERT sentence embeddings from clinical transcript segments for each subject. \n",
    "It reads each transcript CSV, uses BioBERT to embed the 'Text' column, and saves the output with\n",
    "Start_Time, End_Time, and the 768-dimensional BioBERT features to a new CSV file in the same folder.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load BioBERT model\n",
    "BIOBERT_MODEL = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(BIOBERT_MODEL)\n",
    "model = AutoModel.from_pretrained(BIOBERT_MODEL)\n",
    "model.eval()\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Base directory containing subject folders\n",
    "BASE_DIR = \"../data\"\n",
    "\n",
    "# Confidence threshold for filtering low-confidence entries\n",
    "CONFIDENCE_THRESHOLD = 0.7\n",
    "\n",
    "# Function to extract BioBERT embedding from text\n",
    "def get_biobert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    return cls_embedding\n",
    "\n",
    "# Process each subject\n",
    "for subject in os.listdir(BASE_DIR):\n",
    "    if not subject.endswith(\"_P\"):\n",
    "        continue\n",
    "\n",
    "    clinical_dir = os.path.join(BASE_DIR, subject, \"clinical\")\n",
    "    if not os.path.exists(clinical_dir):\n",
    "        print(f\"üö´ Skipping {subject}, no clinical directory.\")\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(clinical_dir):\n",
    "        if not file.endswith(\"_Transcript.csv\"):\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(clinical_dir, file)\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # Identify text column\n",
    "        text_col = \"Text\" if \"Text\" in df.columns else df.columns[2]\n",
    "        if df.empty or df[text_col].isna().all():\n",
    "            print(f\"‚ö†Ô∏è Skipping {subject}, empty or invalid transcript.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"üîç Extracting BioBERT features for {subject} - {file}...\")\n",
    "\n",
    "        output_rows = []\n",
    "\n",
    "        for i, row in tqdm(df.iterrows(), total=len(df), desc=subject):\n",
    "            confidence = row[\"Confidence\"] if \"Confidence\" in row else 1.0\n",
    "            if confidence < CONFIDENCE_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            text = str(row[text_col]) if pd.notna(row[text_col]) else \"\"\n",
    "            start_time = row[\"Start_Time\"] if \"Start_Time\" in row else None\n",
    "            end_time = row[\"End_Time\"] if \"End_Time\" in row else None\n",
    "\n",
    "            embedding = get_biobert_embedding(text)\n",
    "            output_rows.append([start_time, end_time] + embedding.tolist())\n",
    "\n",
    "        # Save final DataFrame with time and features\n",
    "        if output_rows:\n",
    "            feature_cols = [f\"feature_{i}\" for i in range(768)]\n",
    "            output_df = pd.DataFrame(output_rows, columns=[\"Start_Time\", \"End_Time\"] + feature_cols)\n",
    "\n",
    "            output_path = os.path.join(clinical_dir, file.replace(\".csv\", \"_biobert_features.csv\"))\n",
    "            output_df.to_csv(output_path, index=False)\n",
    "\n",
    "            print(f\"‚úÖ Saved BioBERT features to: {output_path}\")\n",
    "            print(f\"üìä Shape: {output_df.shape}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No valid entries for {subject} - {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9917993e-4ef0-4826-9895-35158ee44fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Found clinical folder: ../data/300_P/clinical\n",
      "\n",
      "üîç Found clinical CSV files: ['../data/300_P/clinical/300_Transcript_biobert_features.csv']\n",
      "\n",
      "üìÑ Processing: ../data/300_P/clinical/300_Transcript_biobert_features.csv\n",
      "Initial shape: (70, 770)\n",
      "‚ö†Ô∏è No default_column_names provided, keeping original clinical feature column names.\n",
      "Scaled numeric clinical feature columns.\n",
      "‚úÖ Saved processed file: ../data/300_P/clinical/processed/processed_300_Transcript_biobert_features.csv\n",
      "Shape of saved file: (70, 770)\n",
      "üö´ No clinical folder in: .DS_Store\n",
      "üö´ No clinical folder in: lables\n",
      "\n",
      "üìÇ Found clinical folder: ../data/302_P/clinical\n",
      "\n",
      "üîç Found clinical CSV files: ['../data/302_P/clinical/302_Transcript_biobert_features.csv']\n",
      "\n",
      "üìÑ Processing: ../data/302_P/clinical/302_Transcript_biobert_features.csv\n",
      "Initial shape: (96, 770)\n",
      "‚ö†Ô∏è No default_column_names provided, keeping original clinical feature column names.\n",
      "Scaled numeric clinical feature columns.\n",
      "‚úÖ Saved processed file: ../data/302_P/clinical/processed/processed_302_Transcript_biobert_features.csv\n",
      "Shape of saved file: (96, 770)\n",
      "\n",
      "üìÇ Found clinical folder: ../data/308_P/clinical\n",
      "\n",
      "üîç Found clinical CSV files: ['../data/308_P/clinical/308_Transcript_biobert_features.csv']\n",
      "\n",
      "üìÑ Processing: ../data/308_P/clinical/308_Transcript_biobert_features.csv\n",
      "Initial shape: (143, 770)\n",
      "‚ö†Ô∏è No default_column_names provided, keeping original clinical feature column names.\n",
      "Scaled numeric clinical feature columns.\n",
      "‚úÖ Saved processed file: ../data/308_P/clinical/processed/processed_308_Transcript_biobert_features.csv\n",
      "Shape of saved file: (143, 770)\n",
      "\n",
      "üìÇ Found clinical folder: ../data/301_P/clinical\n",
      "\n",
      "üîç Found clinical CSV files: ['../data/301_P/clinical/301_Transcript_biobert_features.csv']\n",
      "\n",
      "üìÑ Processing: ../data/301_P/clinical/301_Transcript_biobert_features.csv\n",
      "Initial shape: (70, 770)\n",
      "‚ö†Ô∏è No default_column_names provided, keeping original clinical feature column names.\n",
      "Scaled numeric clinical feature columns.\n",
      "‚úÖ Saved processed file: ../data/301_P/clinical/processed/processed_301_Transcript_biobert_features.csv\n",
      "Shape of saved file: (70, 770)\n",
      "üö´ No clinical folder in: .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import glob\n",
    "\n",
    "def preprocess_clinical(input_directory, output_directory, unwanted_columns=[], rename_dict={}, fill_value=0, default_column_names=None):\n",
    "    \"\"\"\n",
    "    Preprocess clinical BioBERT transcript feature CSV files in a given directory:\n",
    "    - Keeps timestamp columns (e.g., Start_Time, End_Time) unchanged.\n",
    "    - Removes unwanted columns and columns containing 'unknown' values.\n",
    "    - Renames columns if needed.\n",
    "    - Fills missing values with fill_value.\n",
    "    - Scales numeric clinical feature columns using StandardScaler.\n",
    "    - Saves processed files in output_directory with 'processed_' prefix.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(input_directory):\n",
    "        print(f\"‚ùå Error: The input directory {input_directory} does not exist!\")\n",
    "        return\n",
    "\n",
    "    # Find all clinical CSV files with the BioBERT feature pattern\n",
    "    clinical_csv_files = glob.glob(os.path.join(input_directory, '*_Transcript_biobert_features.csv'))\n",
    "\n",
    "    if not clinical_csv_files:\n",
    "        print(f\"‚ö†Ô∏è No '_Transcript_biobert_features.csv' files found in {input_directory}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüîç Found clinical CSV files: {clinical_csv_files}\")\n",
    "\n",
    "    for clinical_file in clinical_csv_files:\n",
    "        print(f\"\\nüìÑ Processing: {clinical_file}\")\n",
    "        df = pd.read_csv(clinical_file)\n",
    "        print(f\"Initial shape: {df.shape}\")\n",
    "\n",
    "        # Identify timestamp columns to keep them unchanged\n",
    "        timestamp_cols = ['Start_Time', 'End_Time']\n",
    "        existing_timestamp_cols = [col for col in timestamp_cols if col in df.columns]\n",
    "\n",
    "        # Identify clinical feature columns (exclude timestamps)\n",
    "        clinical_feature_cols = [col for col in df.columns if col not in existing_timestamp_cols]\n",
    "\n",
    "        # If default_column_names provided and matches clinical feature count, rename only clinical feature columns\n",
    "        if default_column_names is not None and len(default_column_names) == len(clinical_feature_cols):\n",
    "            rename_map = dict(zip(clinical_feature_cols, default_column_names))\n",
    "            df.rename(columns=rename_map, inplace=True)\n",
    "            print(f\"‚úÖ Clinical feature columns renamed using default_column_names.\")\n",
    "        elif default_column_names is None:\n",
    "            # If no default names given, keep original clinical feature column names\n",
    "            print(f\"‚ö†Ô∏è No default_column_names provided, keeping original clinical feature column names.\")\n",
    "\n",
    "        # Remove unwanted columns from clinical features\n",
    "        cols_to_drop = [col for col in unwanted_columns if col in df.columns]\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "        if cols_to_drop:\n",
    "            print(f\"Removed unwanted columns: {cols_to_drop}\")\n",
    "\n",
    "        # Remove columns that contain 'unknown' or 'unknow' values anywhere in the column\n",
    "        cols_with_unknowns = [col for col in clinical_feature_cols if df[col].isin(['unknown', 'unknow']).any()]\n",
    "        if cols_with_unknowns:\n",
    "            df.drop(columns=cols_with_unknowns, inplace=True)\n",
    "            print(f\"Removed columns containing 'unknown' values: {cols_with_unknowns}\")\n",
    "\n",
    "        # Rename other columns as per rename_dict (excluding timestamps)\n",
    "        rename_dict_filtered = {k: v for k, v in rename_dict.items() if k in df.columns and k not in existing_timestamp_cols}\n",
    "        if rename_dict_filtered:\n",
    "            df.rename(columns=rename_dict_filtered, inplace=True)\n",
    "            print(f\"Renamed columns as per rename_dict: {rename_dict_filtered}\")\n",
    "\n",
    "        # Fill missing values with fill_value\n",
    "        df.fillna(fill_value, inplace=True)\n",
    "\n",
    "        # Scale numeric clinical feature columns (exclude timestamps)\n",
    "        numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.difference(existing_timestamp_cols)\n",
    "        if not numeric_cols.empty:\n",
    "            scaler = StandardScaler()\n",
    "            df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "            print(f\"Scaled numeric clinical feature columns.\")\n",
    "\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        output_path = os.path.join(output_directory, f\"processed_{os.path.basename(clinical_file)}\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"‚úÖ Saved processed file: {output_path}\")\n",
    "\n",
    "        # Show shape of saved file\n",
    "        saved_df = pd.read_csv(output_path)\n",
    "        print(f\"Shape of saved file: {saved_df.shape}\")\n",
    "\n",
    "\n",
    "def process_all_clinical_participants(root_data_dir):\n",
    "    \"\"\"\n",
    "    Walk through all participant folders in root_data_dir,\n",
    "    locate their 'clinical' subfolders, and preprocess all clinical files found.\n",
    "    Saves processed files inside 'processed' subfolder within each clinical folder.\n",
    "    \"\"\"\n",
    "    for participant_folder in os.listdir(root_data_dir):\n",
    "        participant_path = os.path.join(root_data_dir, participant_folder)\n",
    "        clinical_dir = os.path.join(participant_path, \"clinical\")\n",
    "\n",
    "        if os.path.isdir(clinical_dir):\n",
    "            print(f\"\\nüìÇ Found clinical folder: {clinical_dir}\")\n",
    "            output_dir = os.path.join(clinical_dir, \"processed\")\n",
    "            preprocess_clinical(\n",
    "                input_directory=clinical_dir,\n",
    "                output_directory=output_dir,\n",
    "                unwanted_columns=[\"unwanted_column\"],  # Customize this list as needed\n",
    "                rename_dict={\"old_name\": \"new_name\"},  # Customize renaming as needed\n",
    "                fill_value=0,\n",
    "                default_column_names=None  # Or provide a list of column names for clinical features\n",
    "            )\n",
    "        else:\n",
    "            print(f\"üö´ No clinical folder in: {participant_folder}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_data_dir = \"../data\"\n",
    "    process_all_clinical_participants(root_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b348d-7cb6-428b-a98d-4ae4bd505f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
